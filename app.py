import gradio as gr
from llama_cpp import Llama

# Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Hugging Face
REPO_ID = "Alnabilali1/syper_alnabilali_2025"
MODEL_FILE = "unsloth.F16.gguf"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„
llm = Llama.from_pretrained(
    repo_id=REPO_ID,
    filename=MODEL_FILE,
    n_gpu_layers=0
)

# Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
def chat_with_model(history, message):
    conversation = ""
    for human, bot in history:
        conversation += f"User: {human}\nAssistant: {bot}\n"
    conversation += f"User: {message}\nAssistant:"

    response = llm(conversation, max_tokens=200)
    answer = response["choices"][0]["text"].strip()

    history.append((message, answer))
    return history, ""

# ÙˆØ§Ø¬Ù‡Ø© Chatbot
with gr.Blocks() as demo:
    gr.Markdown("## ðŸ¤– Alnabil AI Chatbot\nØªØ­Ø¯Ø« Ù…Ø¹ Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Hugging Face.")

    chatbot = gr.Chatbot(height=400)
    msg = gr.Textbox(placeholder="Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...")
    clear = gr.Button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")

    state = gr.State([])

    msg.submit(chat_with_model, [state, msg], [chatbot, msg])
    clear.click(lambda: ([], ""), None, [chatbot, msg])

# ØªØ´ØºÙŠÙ„ Ø¹Ù„Ù‰ Railway
demo.launch(server_name="0.0.0.0", server_port=8080)
